Reading frames from a camera or a file is the main bottleneck as copies from the CPU memory to the GPU memory are longer than the processing time. Thus, we load multiple frames at once to reduce the number of system calls and reduce the latency. Then, frames are copied from host to device in batches of a specific size selected by the user. This method circumvents disk access issues and improves substantially the input throughput. Moreover, the entire input data is copied into GPU memory if enough memory is available on the device. Consequently, copies from the GPU file buffer to the GPU input queue are much faster since both memory areas are in the same address space (copy from device to device).