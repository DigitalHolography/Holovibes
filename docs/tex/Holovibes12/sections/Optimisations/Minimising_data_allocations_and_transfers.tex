Handling memory efficiently is crucial when designing software based on an intensive GPU computation pipeline. We used NVIDIA Nsight Systems to analyse GPU memory utilisation and avoid memory re-allocations. As GPU memory allocation is very costly, we allocate all buffers only once when the program starts and free them when the program stops. Similarly, memory transfers between the CPU and the GPU or between buffers were reduced to a strict minimum to limit the number of calls to \textit{cudaMalloc} and \textit{cudaMemcpy}.